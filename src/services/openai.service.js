const OpenAI = require('openai');
const { createEmailGenerationPrompt } = require('../prompts-reference/enhanced-email-prompt');

class OpenAIService {
  constructor() {
    this.client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  async generateStreamWithAssistant(payload, onChunk, assistantId) {
    try {
      if (!assistantId) {
        throw new Error('Assistant ID is required');
      }
      
      console.log('ğŸš€ Starting OpenAI Assistant generation with streaming');
      console.log('ğŸ¤– Using Assistant ID:', assistantId);
      console.log('ğŸ“Š Payload type:', typeof payload);
      console.log('ğŸ“ Payload size:', JSON.stringify(payload).length, 'characters');
      
      // =========================
      // STEP 1: CREATE THREAD
      // =========================
      console.log('\nğŸ“‹ === STEP 1: CREATE THREAD ===');
      console.log('ğŸ”— API Endpoint: POST https://api.openai.com/v1/threads');
      console.log('ğŸ“¦ Request Payload: {}');
      
      const thread = await this.client.beta.threads.create();
      console.log('âœ… Thread created:', thread.id);
      
      // =========================
      // STEP 2: ADD MESSAGE TO THREAD
      // =========================
      console.log('\nğŸ’¬ === STEP 2: ADD MESSAGE TO THREAD ===');
      console.log(`ğŸ”— API Endpoint: POST https://api.openai.com/v1/threads/${thread.id}/messages`);
      
      // Converter payload para string JSON para enviar como content
      const contentToSend = JSON.stringify(payload, null, 2);
      
      const messagePayload = {
        role: 'user',
        content: contentToSend
      };
      
      console.log('ğŸ“¦ === PAYLOAD COMPLETO ENVIADO PARA OPENAI ===');
      console.log(JSON.stringify(messagePayload, null, 2));
      console.log('ğŸ“‹ === CONTEÃšDO DETALHADO ===');
      console.log(contentToSend);
      console.log('='.repeat(50));
      
      await this.client.beta.threads.messages.create(thread.id, messagePayload);
      console.log('âœ… Message added to thread');
      
      // =========================
      // STEP 3: CREATE RUN WITH STREAMING
      // =========================
      console.log('\nğŸƒ === STEP 3: CREATE RUN WITH STREAMING ===');
      console.log(`ğŸ”— API Endpoint: POST https://api.openai.com/v1/threads/${thread.id}/runs`);
      
      const runPayload = {
        assistant_id: assistantId,
        stream: true
      };
      
      console.log('ğŸ“¦ Run Payload:');
      console.log(JSON.stringify(runPayload, null, 2));
      
      const stream = await this.client.beta.threads.runs.stream(thread.id, runPayload);
      console.log('ğŸŒŠ Stream initiated...');

      let fullContent = '';
      let eventCount = 0;
      
      // Process the stream
      console.log('\nğŸ“¥ === STREAMING EVENTS ===');
      for await (const event of stream) {
        eventCount++;
        
        if (eventCount <= 3) {
          console.log(`ğŸ“¨ Event ${eventCount}:`, {
            event: event.event,
            data_type: event.data?.object || 'unknown'
          });
        }
        
        if (event.event === 'thread.message.delta') {
          const delta = event.data.delta;
          if (delta.content && delta.content[0] && delta.content[0].text) {
            const content = delta.content[0].text.value || '';
            if (content) {
              fullContent += content;
              onChunk(content);
            }
          }
        }
      }
      
      console.log(`\nâœ… Assistant stream completed!`);
      console.log(`ğŸ“Š Total events processed: ${eventCount}`);
      console.log(`ğŸ“ Total content length: ${fullContent.length}`);
      
      // Clean up thread
      try {
        console.log(`\nğŸ§¹ Cleaning up thread: ${thread.id}`);
        await this.client.beta.threads.del(thread.id);
        console.log('âœ… Thread cleaned up successfully');
      } catch (cleanupError) {
        console.warn('âš ï¸ Failed to cleanup thread:', cleanupError.message);
      }
      
      return fullContent;
      
    } catch (error) {
      console.error('ğŸ’¥ OpenAI Assistant service error:', error);
      console.error('ğŸ” Error details:', {
        message: error.message,
        status: error.status,
        code: error.code,
        type: error.type
      });
      throw error;
    }
  }

  async generateStreamWithAssistantEnhanced(answers, questions, onChunk, assistantId, batchInfo = null) {
    try {
      if (!assistantId) {
        throw new Error('Assistant ID is required');
      }
      
      if (batchInfo) {
        console.log('ğŸš€ Starting OpenAI Assistant generation with BATCH SYSTEM');
        console.log(`ğŸ“Š Lote: ${batchInfo.batchNumber}/6 (${batchInfo.batchNumber === 6 ? '4' : '5'} emails)`);
      } else {
        console.log('ğŸš€ Starting OpenAI Assistant generation with ENHANCED PROMPT');
      }
      console.log('ğŸ¤– Using Assistant ID:', assistantId);
      console.log(`ğŸ“Š Perguntas: ${questions.length}, Respostas: ${Object.keys(answers).length}`);
      
      // Criar prompt estruturado usando os frameworks anexados (com suporte a lotes)
      const enhancedPrompt = createEmailGenerationPrompt(answers, questions, batchInfo);
      
      console.log('ğŸ“ Enhanced Prompt size:', enhancedPrompt.length, 'characters');
      
      // =========================
      // STEP 1: CREATE THREAD
      // =========================
      console.log('\nğŸ“‹ === STEP 1: CREATE THREAD ===');
      const thread = await this.client.beta.threads.create();
      console.log('âœ… Thread created:', thread.id);
      
      // =========================
      // STEP 2: ADD MESSAGE TO THREAD
      // =========================
      console.log('\nğŸ’¬ === STEP 2: ADD MESSAGE TO THREAD ===');
      
      const messagePayload = {
        role: 'user',
        content: enhancedPrompt
      };
      
      console.log('ğŸ“¦ === PROMPT ESTRUTURADO ENVIADO ===');
      console.log('Primeiros 500 caracteres:');
      console.log(enhancedPrompt.substring(0, 500) + '...');
      console.log('='.repeat(50));
      
      await this.client.beta.threads.messages.create(thread.id, messagePayload);
      console.log('âœ… Enhanced message added to thread');
      
      // =========================
      // STEP 3: CREATE RUN WITH STREAMING
      // =========================
      console.log('\nğŸƒ === STEP 3: CREATE RUN WITH STREAMING ===');
      
      const runPayload = {
        assistant_id: assistantId,
        stream: true
      };
      
      const stream = await this.client.beta.threads.runs.stream(thread.id, runPayload);
      console.log('ğŸŒŠ Enhanced stream initiated...');

      let fullContent = '';
      let eventCount = 0;
      
      // Process the stream
      console.log('\nğŸ“¥ === STREAMING EVENTS ===');
      for await (const event of stream) {
        eventCount++;
        
        if (eventCount <= 3) {
          console.log(`ğŸ“¨ Event ${eventCount}:`, {
            event: event.event,
            data_type: event.data?.object || 'unknown'
          });
        }
        
        if (event.event === 'thread.message.delta') {
          const delta = event.data.delta;
          if (delta.content && delta.content[0] && delta.content[0].text) {
            const content = delta.content[0].text.value || '';
            if (content) {
              fullContent += content;
              onChunk(content);
            }
          }
        }
      }
      
      console.log(`\nâœ… Enhanced Assistant stream completed!`);
      console.log(`ğŸ“Š Total events processed: ${eventCount}`);
      console.log(`ğŸ“ Total content length: ${fullContent.length}`);
      
      // Clean up thread
      try {
        console.log(`\nğŸ§¹ Cleaning up thread: ${thread.id}`);
        await this.client.beta.threads.del(thread.id);
        console.log('âœ… Thread cleaned up successfully');
      } catch (cleanupError) {
        console.warn('âš ï¸ Failed to cleanup thread:', cleanupError.message);
      }
      
      return fullContent;
      
    } catch (error) {
      console.error('ğŸ’¥ OpenAI Enhanced Assistant service error:', error);
      console.error('ğŸ” Error details:', {
        message: error.message,
        status: error.status,
        code: error.code,
        type: error.type
      });
      throw error;
    }
  }

  // Aliases for backward compatibility
  async generateEmailsStream(formattedAnswers, onChunk) {
    throw new Error('Use generateStreamWithAssistant with specific assistant ID instead');
  }

  async generateEditorialAnalysisStream(formattedAnswers, onChunk) {
    throw new Error('Use generateStreamWithAssistant with specific assistant ID instead');
  }

  async generateMessagesStream(formattedAnswers, onChunk) {
    throw new Error('Use generateStreamWithAssistant with specific assistant ID instead');
  }
}

module.exports = new OpenAIService();